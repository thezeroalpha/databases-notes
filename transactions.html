<html>
<head>
    <link rel="Stylesheet" type="text/css" href="style.css" />
    <title>transactions</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <script type="text/javascript" async src="https://cdn.jsdelivr.net/gh/mathjax/MathJax@2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<style type="text/css">
nav a {
    text-align: left;
}
nav #name {
    text-align: right;
    float: right;
    font-style: italic;
}
</style>
    <nav>
    <a href="index.html">Index</a>
    <span id="name">Alex Balgavy</span>
    </nav>
    <hr>
    <div class="content">
    
<div id="Transactions"><h2 id="Transactions" class="header"><a href="#Transactions">Transactions</a></h2></div>
<p>
transaction: a sequence of actions we want to perform on a database
</p>

<p>
should be atomic: either run fully, or not at all.
this avoids concurrency problems like:
</p>
<ul>
<li>
losing effects of one transaction due to uncontrolled overwrite by another ('lost update anomaly')

<li>
transaction reads partial result of another transaction ('inconsistent read anomaly')

<li>
transaction reads changes made by another transaction before they are rolled back ('dirty read anomaly')

<li>
transaction reads value which is afterwards changed by another transaction ('unrepeatable read anomaly')

</ul>

<p>
For this, we need to get some ACID:
</p>
<ul>
<li>
Atomicity: transaction executes fully or not at all (commit or abort)

<li>
Consistency: transactions always leave database in consistent state, where all defined integrity constraints hold

<li>
Isolation: multiple users can modify database at the same time without seeing partial actions

<li>
Durability: when transaction is committed successfully, the data is persistent, regardless of crashes

</ul>

<p>
transaction: a list of actions
</p>
<ul>
<li>
reads - R(O)

<li>
writes - W(O)

<li>
end with Commit or Abort

<li>
e.g.: T₁: R(V)&lt; R(Y), W(V), W(C), Commit

</ul>

<div id="Transactions-Schedules"><h3 id="Schedules" class="header"><a href="#Transactions-Schedules">Schedules</a></h3></div>
<p>
scheduler decides execution order of concurrent database access
</p>

<p>
schedule is list of actions from set of transactions ('plan on how to execute transactions'). order in which 2 actions of transaction T appear in schedule must be same as order in T.
</p>

<div id="Transactions-Serializability"><h3 id="Serializability" class="header"><a href="#Transactions-Serializability">Serializability</a></h3></div>
<p>
serial schedule: if actions of different transactions are executed one after another (e.g. all of T2, then all of T1)
</p>

<p>
serializable schedule: if its effect on database is same as that of some serial schedule
</p>

<p>
actions in schedule conflict if they
</p>
<ul>
<li>
are from different transactions

<li>
and involve same data item

<li>
and one action is write

</ul>

<p>
conflicts may cause schedule to not be serializable
</p>

<p>
conflict types:
</p>
<ul>
<li>
write read (WR) - T₁ writes Y, then T₂ reads Y

<li>
read write (RW) - T₁ reads Y, then T₂ writes Y

<li>
write write (WW) - T₁ writes Y, then T₂ writes Y

</ul>

<p>
we can swap actions of different transactions if actions are non-conflicting.
</p>

<p>
conflict equivalent schedules: if they can be transformed into each other by swapping non-conflicting, adjacent transactions.
</p>

<p>
conflict-serializable: if conflict equivalent to some serial schedule
</p>

<p>
check it with a precedence graph:
</p>
<ul>
<li>
graph has node for each transaction

<li>
edge from T₁ to T₂ if conflicting action between T₁ and T₂ (with T₁ first)

<li>
conflict-serializable iff no cycle in the graph

<li>
if no cycles, serial schedule is a topological sort of precedence graph

</ul>

<div id="Transactions-Runtime serializability strategies"><h3 id="Runtime serializability strategies" class="header"><a href="#Transactions-Runtime serializability strategies">Runtime serializability strategies</a></h3></div>
<p>
serializability during runtime: system doesn't know which transactions will run, and which items they'll access
</p>

<p>
strategies:
</p>
<ul>
<li>
Pessimistic: lock-based, timestamp based

<li>
Optimistic: read-set/write-set tracking, validation before commit

<li>
Multi-version techniques: eliminate concurrency control overhead for read-only queries

</ul>

<div id="Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking"><h4 id="Pessimistic: lock-based, two phase locking" class="header"><a href="#Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking">Pessimistic: lock-based, two phase locking</a></h4></div>
<p>
transactions must lock objects before using them
</p>

<p>
types:
</p>
<ul>
<li>
shared lock (S-lock): acquired on Y before <em>reading</em> Y, many transactions can hold a shared lock on Y

<li>
exclusive lock (X-lock): acquired on Y before <em>writing</em> Y. transaction can hold exclusive lock on Y if no other transaction holds a lock on Y.

</ul>

<p>
2 phase locking protocol:
</p>
<ul>
<li>
each transaction must get:

<ul>
<li>
S-lock on object before reading it

<li>
X-lock on object before writing it

</ul>
<li>
transaction can't get new locks once it releases any lock

<li>
any schedule that conforms to 2PL is conflict-serializable

</ul>

<div id="Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking-Deadlock handling"><h5 id="Deadlock handling" class="header"><a href="#Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking-Deadlock handling">Deadlock handling</a></h5></div>
<p>
2 PL has the risk of deadlocks where both transactions wait for each other indefinitely. need to detect deadlock.
</p>

<p>
detection with Wait-for-Graphs
</p>
<ul>
<li>
system maintains wait-for-graph, where nodes are transactions and edges A→B mean A is waiting for B to release lock

<li>
system periodically checks for graph cycles

<li>
if cycle detected, you abort a transaction

<li>
selecting the victim is a challenge:

<ul>
<li>
if you abort a young one, there will be starvation

<li>
if you abort an old one, you'll be throwing away what you invested in it

<li>
phrasing, dude.

</ul>
</ul>

<p>
detection with timeout
</p>
<ul>
<li>
let transactions block on a lock request for a limited time

<li>
after timeout, assume deadlock and abort T

</ul>

<div id="Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking-Cascading rollbacks"><h5 id="Cascading rollbacks" class="header"><a href="#Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking-Cascading rollbacks">Cascading rollbacks</a></h5></div>
<p>
cascadeless schedule
</p>
<ul>
<li>
delay reads, only read value produced by already committed transactions

<li>
so if a value is required, wait for the commit

<li>
no dirty reads, so abort doesn't cascade

</ul>

<p>
recoverable schedule:
</p>
<ul>
<li>
delay commit - if T2 reads value written by T1, commit of T2 has to wait until after commit of T1

</ul>

<p>
schedules should always be recoverable. all cascadeless schedules are recoverable.
</p>

<div id="Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking-Strict 2 phase locking"><h5 id="Strict 2 phase locking" class="header"><a href="#Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking-Strict 2 phase locking">Strict 2 phase locking</a></h5></div>
<p>
same as 2PL, but a transaction releases all locks only when it's completed (commit/rollback).
it's cascadeless, but still has deadlocks.
</p>

<div id="Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking-Preclaiming 2 phase locking"><h5 id="Preclaiming 2 phase locking" class="header"><a href="#Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking-Preclaiming 2 phase locking">Preclaiming 2 phase locking</a></h5></div>
<p>
all needed locks are declared at start of transaction.
therefore, no deadlocks.
however, not applicable in multi-query transactions (where queries might depend on results of previous queries)
</p>

<div id="Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking-Granularity of locking"><h5 id="Granularity of locking" class="header"><a href="#Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking-Granularity of locking">Granularity of locking</a></h5></div>
<p>
there's a tradeoff.
the more specific your locking is (database, vs table, vs row level), the higher concurrency you have, and the higher overhead
</p>

<p>
multi-granularity locking - decide granularity of locks held for each transaction depending on characteristics of transaction
</p>

<p>
intention locks (do not conflict with each other):
</p>
<ul>
<li>
intention share (IS)

<li>
intention exclusive (IX)

</ul>

<p>
an intention lock on coarser level of granularity means there is S/X lock on finer level of granularity.
</p>

<p>
before a granule <em>g can</em> be locked in S/X mode, the transaction has to obtain an IS/IX lock on all coarser granularities containing <em>g</em>
</p>

<p>
after all intention locks are granted, transaction can lock <em>g</em> in the announced mode
</p>

<p>
levels of granularity: database → table → row
</p>

<div id="Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking-Optimising performance"><h5 id="Optimising performance" class="header"><a href="#Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking-Optimising performance">Optimising performance</a></h5></div>
<p>
for each query in log:
</p>
<ul>
<li>
analyse average time and variance for this type of query

<ul>
<li>
if long delays or frequently aborts, might be contention

</ul>
<li>
read only or updating query?

<ul>
<li>
compute read-sets, write-sets

<li>
will it require row/table locks? shared/exclusive?

</ul>
</ul>

<p>
How do read- and write-sets of queries intersect? What is chance of conflicts?
</p>

<p>
When you understand the query workload, you can:
</p>
<ul>
<li>
rewrite queries for smaller read- and write-sets

<li>
change scheduling of queries to reduce contention

<li>
use different isolation level for queries

</ul>

<div id="Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking-Isolation levels"><h5 id="Isolation levels" class="header"><a href="#Transactions-Runtime serializability strategies-Pessimistic: lock-based, two phase locking-Isolation levels">Isolation levels</a></h5></div>
<p>
some degree of inconsistency may be acceptable to get increased concurrency &amp; performance
</p>

<p>
SQL-92 levels:
</p>
<ul>
<li>
<code>read uncommitted</code>: only write locks acquired, any row read can be concurrently changed by other transactions

<li>
<code>read committed</code>: read locks held for as long as application cursor sits on a current row, write locks as usual

<li>
<code>repeatable read</code>: strict 2PL, a transaction may read phantom rows if it runs an aggregation query twice

<li>
<code>serializable</code>: strict 2PL, multi-granularity locking. no phantom rows.

</ul>

<p>
<img src="img/sql-92-isolation-levels.png" alt="SQL-92 isolation levels" />
</p>

<p>
phantom row problem: T1 locks all rows, but T2 inserts new row that isn't locked.
</p>

<p>
solutions:
</p>
<ul>
<li>
multi-granularity locking (locking the table)

<li>
declarative locking - key-range or predicate locking

</ul>

<p>
many applications don't need full serializability, selecting a weaker but acceptable isolation level is part of database tuning.
</p>

<div id="Transactions-Runtime serializability strategies-Optimistic concurrency control"><h4 id="Optimistic concurrency control" class="header"><a href="#Transactions-Runtime serializability strategies-Optimistic concurrency control">Optimistic concurrency control</a></h4></div>
<p>
hope for the best, only check that no conflicts happened when committing. this saves locking overhead.
</p>

<p>
three phases:
</p>
<ol>
<li>
Read phase: execute transaction, but don't write data to disk. collect updates in transaction's private workspace

<li>
Validation phase: when transaction wants to commit, DBMS test whether execution correct, and abort if needed.

<li>
Write phase: transfer data from private workspace into database.

</ol>

<p>
Phases 2, 3 have to be in non-interruptible critical section (val-write phase).
</p>

<div id="Transactions-Runtime serializability strategies-Optimistic concurrency control-Validation"><h5 id="Validation" class="header"><a href="#Transactions-Runtime serializability strategies-Optimistic concurrency control-Validation">Validation</a></h5></div>
<p>
typically implemented by maintaining:
</p>
<ul>
<li>
read set RS(Tk) - attributes read by Tk

<li>
write set Ws(Tk) - attributes written by Tk

</ul>

<p>
Backward-oriented optimistic concurrency control (BOCC)
</p>
<ul>
<li>
on commit, compare Tk against all <em>committed</em> transactions Ti

<li>
succeeds if

<ul>
<li>
Ti committed before Tk started

<li>
or Rs(Tk) ∩ WS(Ti) = Ø

</ul>
</ul>

<p>
Forward-oriented optimistic concurrency control (FOCC)
</p>
<ul>
<li>
on commit, compare Tk against all <em>running</em> transactions Ti

<li>
succeeds if

<ul>
<li>
Ws(Tk) ∩ RS(Ti) = Ø

</ul>
</ul>

<div id="Transactions-Runtime serializability strategies-Optimistic concurrency control-Multiversion concurrency control"><h5 id="Multiversion concurrency control" class="header"><a href="#Transactions-Runtime serializability strategies-Optimistic concurrency control-Multiversion concurrency control">Multiversion concurrency control</a></h5></div>
<p>
with old object versions around, read-only transactions never need to be blocked
</p>
<ul>
<li>
might see outdated but consistent version of data

<li>
like everything in query happened the moment it started

</ul>

<p>
issues:
</p>
<ul>
<li>
versioning requires space and management overhead

<li>
update transactions still need concurrency control

</ul>

<p>
snapshot isolation: 
</p>
<ul>
<li>
each transaction sees consistent snapshot of database corresponding to state at moment it started

<li>
read-only transactions don't have to lock anything

<li>
transactions conflict if write to same object

<ul>
<li>
pessimistic concurrency control - only writes are locked

<li>
optimistic concurrency control - only write-sets interesting

</ul>
<li>
does not guarantee serializability

<li>
avoids dirty read, unrepeatable read, phantom rows

<li>
introduces write skew, with complex assertions involving multiple tuples

</ul>

    </div>
</body>
</html>
